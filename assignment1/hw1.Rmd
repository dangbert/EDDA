---
title: "Assignment 1: Group 45"
author: "Daniel Engbert, Rik Timmer, Koen van der Pool"
date: "11 February 2023"
output: pdf_document
fontsize: 11pt
highlight: tango
editor_options: 
  markdown: 
    wrap: 72
---

## Exercise 1: Birthweights

<!--# See template_assign_edda.Rmd for full tips and info for formatting this document -->

**a)**

<!--# print(sprintf("96%% confidence interval: [%.4f, %.4f]", res$conf.int[1], res$conf.int[2])) -->

```{r}
data = read.table("birthweight.txt", header=T)
par(mfrow=c(1,2))
# use x as alias for the dataset
x = data$birthweight

# checking normality
hist(x, freq=F)
qqnorm(x)
shapiro.test(x)

t.test(x, conf.level=0.96)

# calculate min sample size needed
tval = qt(0.98, length(x))
m = 50
n = (tval * sd(x) / m) ** 2
print(sprintf("min sample size, n = %.2f", n))

```

The birthweight data appears to be normal based on a normal-appearing
histogram, the straight line in the qqplot, and the shapiro-wilk
normality test (having $p=0.8995 > 0.05$).

$$
m = \frac{t*s}{\sqrt{n}} \rightarrow n = (\frac{t * s}{m})^2
$$

The equation above, gives the sample size, $n$, needed for the
confidence interval to have a width of 100 (meaning $m=50$), where $t$
is the t-score for the quantile 0.02 (such that both tails of the
distribution have total area $1-0.96=0.04$). Our R code above computes
$n = 832.32$, which rounded up indicates the min sample size is $n=833$
(for a 96% CI of length at most 100).

```{r}
B = 10000
Tstar = numeric(B)
for (i in 1:B){
  # sample with replacement, for a new sample of same length(x)
  Xstar = sample(x, replace=TRUE)
  Tstar[i] = mean(Xstar) 
}

Tstar02 = quantile(Tstar, 0.02)
Tstar04 = quantile(Tstar, 0.98)
print(sprintf("Bootstrap 96%% CI = [%.2f, %.2f]", Tstar02, Tstar04))
```

The output of our bootstrap 96% CI indicates that we can say with 96%
confidence that the true mean weight of newborn babies is between
`r sprintf("[%.2f, %.2f]", Tstar02, Tstar04)` grams. This is
approximately consistent with the CI calculated previously (as
expected).

<!-- TODO: note that what we did above was a "percentile boostrap CI", maybe we should do the other version?  See Lecture2, slide 6+9-->

**b)**

```{r}
res = t.test(x, mu=2800, alt="g")
res #[[4]]
```

The output of the confidence interval here denotes that we can say with
95% confidence that the true mean is in the interval
`r sprintf("[%.4f, %.4f]", res$conf.int[[1]], res$conf.int[[2]])`, and
with a p-value of `r sprintf("%.4f", res$p.value)` \< 0.05, we can
accept the alternative hypothesis from the expert that the mean
birthweight $\mu > 2800$ grams.

As we previously determined, the data is approximately normally
distributed, and symmetric. Therefore the difference between the mean
and median is minimal, and we can use a Wilcoxon signed rank test for
one sample.

```{r}
res = wilcox.test(x, mu=2800, alt="g")
res
```

The resulting p-value of `r sprintf("%.4f", res$p.value)` \< 0.05 also
supports accepting the alternative hypothesis from the expert that
$\mu > 2800$ grams.

**c)**

```{r}

B = 10000; n = length(x)
psign=numeric(B) ## will contain p-values of sign test
pttest=numeric(B) ## will contain p-values of t-test
for(i in 1:B) {
  y = rnorm(n, mean=mean(x),sd=sd(x)) ## generate data under H1 with mu=0.5
  mu = 2800
  pttest[i] = t.test(y, mu=mu, alternative="greater")[[3]] ## extract p-value
  psign[i] = wilcox.test(y, mu=mu, alt="g")[[3]]
  #psign[i] = binom.test(sum(x>0),n,p=0.5)[[3]]
} ## extract p-value
signPower = sum(psign<0.05) / B
tPower = sum(pttest<0.05) / B

print(sprintf("wilcox signed rank test power = %.4f, t-test power = %.4f", signPower, tPower))
par(mfrow=c(1,2))
hist(psign)
hist(pttest)

```

Our simulation results suggest that for this problem, the power of the
t-test is `r sprintf("%.4f", tPower)`, and the power of Wilcoxon sign
test is `r sprintf("%.4f", signPower)`.

**d)**

```{r}
# compute pHat based on the data:
pHat = sum(x < 2600) / length(x)
n = length(x)
# compute z_{\alpha/2}
z = (pHat - 0.25) / sqrt((pHat * (1-pHat)) / n)
sprintf("pHat = %.5f, z = %.5f", pHat, z)
# compute alpha:
alpha = 2 * pnorm(z, lower.tail = F)
ciLevel = 1 - alpha
sprintf("confidence interval level = %.5f", ciLevel)

ciUpper = pHat + z * sqrt((pHat * (1-pHat)) / n)
ciLower = pHat - z * sqrt((pHat * (1-pHat)) / n)
sprintf("final confidence interval = [%.4f, %.4f]", ciLower, ciUpper)
```

$$
0.25 = \hat{p} - z_{\alpha/2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}
\rightarrow z_{\alpha/2} = \frac{\hat{p} - 0.25}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}}
$$

We compute $\hat{p}$ from the data, use it to solve for $z_{\alpha/2}$,
allowing us to compute that \$\\alpha = 0.01\$. So the original
confidence interval was at 98% level, and in our code above we compute
the full confidence interval
`r sprintf("final confidence interval = [%.4f, %.4f]", ciLower, ciUpper)`.

<!--# TODO: think about if we should have used t-value instead?  -->

**\
e)**

```{r}
prop.test(c(34, 28), c(95, 93))
#prop.test(c(34, 28), c(95, 93))
```

Considering male and female babies to be two separate populations, we'll
call a "success" when a baby is born \< 2600 grams. So we do a
proportion test comparing the "successes" of each respective population
($34/95$ vs $28/93$), and the resulting p-value $p=0.5007 > 0.05$
indicates we fail to reject the $H_0$ that the proportion of babies born
\< 2600 grams differs between the male and female populations.

So the expert's claim, is rejected (this conclusion is the best we can
do with the data we have).

<!--#  TODO: how do we connect this to the statement about means??? -->

## Exercise 2: Cholesterol

**a)**

```{r,echo=FALSE,fig.height=3.5}
data = read.table("cholesterol.txt", header=T)

plot(data$Before, data$After8weeks, main="Scatter Plot of Cholestrol Before vs After Treatment", xlab="Cholestrol Before (mmol/L)", ylab="Cholestrol After (mmol/L)")

# checking normality:
par(mfrow=c(1,2))
hist(data$Before, freq=F)
qqnorm(data$Before)
shapiro.test(data$Before)

hist(data$After8weeks, freq=F)
qqnorm(data$After8weeks)
shapiro.test(data$After8weeks)
```

Based on the histograms, qqplots and shapiro-Wilk normality test results
(both variables having $p>0.05$), both variables (`Before`,
`After8Weeks`) appear to be normally distributed.

As both variables appear to be normal, we can use the pearson's
correlation test (instead of spearman's) to test the correlation between
them.

```{r}
cor.test(data$Before, data$After8weeks)
```

The pearson's correlation test produces a correlation coefficient of
$0.9909$, which is very close to 1.0, which suggests that indeed there
is a strong positive correlation between the cholestrol levels `Before`
and `After8Weeks` .

**b)**

In this experiment, the data are paired because a given index $i$ into
the two variables, contains a value measured from the same experimental
unit (person) before and after receiving a treatment (a low fat diet in
this case).

To investigate whether the diet had an effect, we can use a paired
t-test, and a sign test.

In this experiment, the data are paired as each experimental unit
(person) had their cholesterol measured before and after treatment.

TODO: explain $H_0$

```{r}

```

Permutation test could also be used here because we have two paired
samples, and no assumptions are needed.

**c)**

Based on the sample of cholesterol after 8 weeks, we can compute a CI
for the population's average using:

$$
\bar{X} \pm t_{\alpha/2}\frac{s}{\sqrt{n}}
$$

And given the uniform distribution $unif(3, \theta)$ has mean
$\mu = \frac{\theta+3}{2} \rightarrow \theta = 2*\mu+3$, so we can
compute theta from our CI for xbar.

```{r}
xbar = mean(data$After8weeks)
s = sd(data$After8weeks)
n = length(data$After8weeks)
#qt(0.95, df=n-1)

m = qt(0.95, df=n-1) * (s / sqrt(n))
# compute CI for \bar{x}
xBarLow = xbar - m
xBarHigh = xbar + m
sprintf("CI for xbar = [%.4f, %.4f]", xBarLow, xBarHigh)

# use results to compute CI for \theta
thetaLow = 2 * xBarLow - 3
thetaHigh = 2 * xBarHigh - 3
sprintf("CI for theta = [%.4f, %.4f]", thetaLow, thetaHigh)
```

**d)**

```{r}
# returns TRUE if X ~Unif(3, theta) is plausible (p > 0.05)
doBootstrap = function (x, theta, makePlot=FALSE) {
  n = length(x)
  t = max(x)
  B = 4000
  tstar = numeric(B)
  for (i in 1:B) {
    xstar = runif(n, min=3, max=theta)
    tstar[i] = max(xstar)
  }
  
  pl = sum(tstar<t) / B
  pr = sum(tstar>t) / B
  p = 2 * min(pl, pr) # e.g. 0.038
  
  if (makePlot) {
  # make histogram:
    hist(tstar,prob=T, main="Histogram of tstar", freq=F)
    lines(rep(t,2), c(0,0.03), col="red", lwd=2)
    axis(1,t,expression(paste("t")))
    print(sprintf("p = %.4f", p))
  }
  #return(p >= 0.05);
  return(data.frame(theta=theta, p=p, valid=(p>=0.05)))
}

#results = data.frame(p=c(), valid=c())
results = NULL
for (theta in seq(3,12,0.25)){
  cur = 
    doBootstrap(data$After8weeks, theta, makePlot=FALSE)
  if (is.null(results)) {
    results = cur
  } else {
    results = rbind(results, cur)
  }
}
plot(results$theta, results$p, main="P value vs Theta")
results
#sprintf("res = %d", res)
```

**e)**

```{r}

```

## Exercise 3: Diet

```{r}
data = read.table("diet.txt", header=T)
#data
```

## Exercise 4: Yield of Peas

```{r}
library(MASS)
data = npk
#data
```
