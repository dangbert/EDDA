---
title: "Assignment 1: Group 45"
author: "Daniel Engbert, Rik Timmer, Koen van der Pool"
date: "11 February 2023"
output: pdf_document
fontsize: 11pt
highlight: tango
editor_options: 
  markdown: 
    wrap: 72
---

## Exercise 1: Birthweights

<!--# See template_assign_edda.Rmd for full tips and info for formatting this document -->

**a)**

<!--# print(sprintf("96%% confidence interval: [%.4f, %.4f]", res$conf.int[1], res$conf.int[2])) -->

```{r}
data = read.table("birthweight.txt", header=T)
par(mfrow=c(1,2))
# use x as alias for the dataset
x = data$birthweight

# checking normality
hist(x, freq=F)
qqnorm(x)
shapiro.test(x)

t.test(x, conf.level=0.96)

# calculate min sample size needed
tval = qt(0.98, length(x))
m = 50
n = (tval * sd(x) / m) ** 2
print(sprintf("min sample size, n = %.2f", n))

```

The birthweight data appears to be normal based on a normal-appearing
histogram, the straight line in the qqplot, and the shapiro-wilk
normality test (having $p=0.8995 > 0.05$).

$$
m = \frac{t*s}{\sqrt{n}} \rightarrow n = (\frac{t * s}{m})^2
$$

The equation above, gives the sample size, $n$, needed for the
confidence interval to have a width of 100 (meaning $m=50$), where $t$
is the t-score for the quantile 0.02 (such that both tails of the
distribution have total area $1-0.96=0.04$). Our R code above computes
$n = 832.32$, which rounded up indicates the min sample size is $n=833$
(for a 96% CI of length at most 100).

```{r}
B = 10000
Tstar = numeric(B)
for (i in 1:B){
  # sample with replacement, for a new sample of same length(x)
  Xstar = sample(x, replace=TRUE)
  Tstar[i] = mean(Xstar) 
}

Tstar02 = quantile(Tstar, 0.02)
Tstar04 = quantile(Tstar, 0.98)
print(sprintf("Bootstrap 96%% CI = [%.2f, %.2f]", Tstar02, Tstar04))
```

The output of our bootstrap 96% CI indicates that we can say with 96%
confidence that the true mean weight of newborn babies is between
`r sprintf("[%.2f, %.2f]", Tstar02, Tstar04)` grams. This is
approximately consistent with the CI calculated previously (as
expected).

<!-- TODO: note that what we did above was a "percentile boostrap CI", maybe we should do the other version?  See Lecture2, slide 6+9-->

**b)**

```{r}
res = t.test(x, mu=2800, alt="g")
res #[[4]]
```

The output of the confidence interval here denotes that we can say with
95% confidence that the true mean is in the interval
`r sprintf("[%.4f, %.4f]", res$conf.int[[1]], res$conf.int[[2]])`, and
with a p-value of `r sprintf("%.4f", res$p.value)` \< 0.05, we can
accept the alternative hypothesis from the expert that the mean
birthweight $\mu > 2800$ grams.

As we previously determined, the data is approximately normally
distributed, and symmetric. Therefore the difference between the mean
and median is minimal, and we can use a Wilcoxon signed rank test for
one sample.

```{r}
res = wilcox.test(x, mu=2800, alt="g")
res
```

The resulting p-value of `r sprintf("%.4f", res$p.value)` \< 0.05 also
supports accepting the alternative hypothesis from the expert that
$\mu > 2800$ grams.

**c)**

```{r}

B = 10000; n = length(x)
psign=numeric(B) ## will contain p-values of sign test
pttest=numeric(B) ## will contain p-values of t-test
for(i in 1:B) {
  y = rnorm(n, mean=mean(x),sd=sd(x)) ## generate data under H1 with mu=0.5
  mu = 2800
  pttest[i] = t.test(y, mu=mu, alternative="greater")[[3]] ## extract p-value
  psign[i] = wilcox.test(y, mu=mu, alt="g")[[3]]
  #psign[i] = binom.test(sum(x>0),n,p=0.5)[[3]]
} ## extract p-value
signPower = sum(psign<0.05) / B
tPower = sum(pttest<0.05) / B

print(sprintf("wilcox signed rank test power = %.4f, t-test power = %.4f", signPower, tPower))
par(mfrow=c(1,2))
hist(psign)
hist(pttest)

```

Our simulation results suggest that for this problem, the power of the
t-test is `r sprintf("%.4f", tPower)`, and the power of Wilcoxon sign
test is `r sprintf("%.4f", signPower)`.

**d)**

```{r}
# compute pHat based on the data:
pHat = sum(x < 2600) / length(x)
n = length(x)
# compute z_{\alpha/2}
z = (pHat - 0.25) / sqrt((pHat * (1-pHat)) / n)
sprintf("pHat = %.5f, z = %.5f", pHat, z)
# compute alpha:
alpha = 2 * pnorm(z, lower.tail = F)
ciLevel = 1 - alpha
sprintf("confidence interval level = %.5f", ciLevel)

ciUpper = pHat + z * sqrt((pHat * (1-pHat)) / n)
ciLower = pHat - z * sqrt((pHat * (1-pHat)) / n)
sprintf("final confidence interval = [%.4f, %.4f]", ciLower, ciUpper)
```

$$
0.25 = \hat{p} - z_{\alpha/2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}
\rightarrow z_{\alpha/2} = \frac{\hat{p} - 0.25}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}}
$$

We compute $\hat{p}$ from the data, use it to solve for $z_{\alpha/2}$,
allowing us to compute that \$\\alpha = 0.01\$. So the original
confidence interval was at 98% level, and in our code above we compute
the full confidence interval
`r sprintf("final confidence interval = [%.4f, %.4f]", ciLower, ciUpper)`.

<!--# TODO: think about if we should have used t-value instead?  -->

**\
e)**

```{r}
prop.test(c(34, 28), c(95, 93))
#prop.test(c(34, 28), c(95, 93))
```

Considering male and female babies to be two separate populations, we'll
call a "success" when a baby is born \< 2600 grams. So we do a
proportion test comparing the "successes" of each respective population
($34/95$ vs $28/93$), and the resulting p-value $p=0.5007 > 0.05$
indicates we fail to reject the $H_0$ that the proportion of babies born
\< 2600 grams differs between the male and female populations.

So the expert's claim, is rejected (this conclusion is the best we can
do with the data we have).

<!--#  TODO: how do we connect this to the statement about means??? -->

## Exercise 2: Cholesterol

**a)**

```{r,echo=FALSE,fig.height=3.5}
data = read.table("cholesterol.txt", header=T)

plot(data$Before, data$After8weeks, main="Scatter Plot of Cholestrol Before vs After Treatment", xlab="Cholestrol Before (mmol/L)", ylab="Cholestrol After (mmol/L)")

# checking normality:
par(mfrow=c(1,2))
hist(data$Before, freq=F)
qqnorm(data$Before)
shapiro.test(data$Before)

hist(data$After8weeks, freq=F)
qqnorm(data$After8weeks)
shapiro.test(data$After8weeks)
```

Based on the histograms, qqplots and shapiro-Wilk normality test results
(both variables having $p>0.05$), both variables (`Before`,
`After8Weeks`) appear to be normally distributed.

As both variables appear to be normal, we can use the pearson's
correlation test (instead of spearman's) to test the correlation between
them.

```{r}
cor.test(data$Before, data$After8weeks)
```

The pearson's correlation test produces a correlation coefficient of
$0.9909$, which is very close to 1.0, which suggests that indeed there
is a strong positive correlation between the cholestrol levels `Before`
and `After8Weeks` .

**b)**

In this experiment, the data are paired because a given index $i$ into
the two variables, contains a value measured from the same experimental
unit (person) before and after receiving a treatment (a low fat diet in
this case).

To investigate whether the diet had an effect, we can use a paired
t-test, and a sign test.

In this experiment, the data are paired as each experimental unit
(person) had their cholesterol measured before and after treatment.

TODO: explain $H_0$

```{r}

```

Permutation test could also be used here because we have two paired
samples, and no assumptions are needed.

**c)**

Based on the sample of cholesterol after 8 weeks, we can compute a CI
for the population's average using:

$$
\bar{X} \pm t_{\alpha/2}\frac{s}{\sqrt{n}}
$$

And given the uniform distribution $unif(3, \theta)$ has mean
$\mu = \frac{\theta+3}{2} \rightarrow \theta = 2*\mu+3$, so we can
compute theta from our CI for xbar.

```{r}
xbar = mean(data$After8weeks)
s = sd(data$After8weeks)
n = length(data$After8weeks)

m = qt(0.975, df=n-1) * (s / sqrt(n))
# compute CI for \bar{x}
xBarLow = xbar - m
xBarHigh = xbar + m
sprintf("CI for xbar = [%.4f, %.4f]", xBarLow, xBarHigh)

# use results to compute CI for \theta
thetaLow = 2 * xBarLow - 3
thetaHigh = 2 * xBarHigh - 3
sprintf("CI for theta = [%.4f, %.4f]", thetaLow, thetaHigh)
```

This CI can be slightly improved, because given the max value in
After8Weeks is 7.6700, we know that $\theta$ must be $\ge 7.600$ in
order to have generated this data.

So we can slightly adjust our CI to be:

```{r}
sprintf("max(data$After8weeks) = %.4f", max(data$After8weeks))
sprintf("improved CI = [%.4f, %.4f]",  max(data$After8weeks), thetaHigh)
```

**d)**

```{r}
# returns TRUE if X ~Unif(3, theta) is plausible (p > 0.05)
doBootstrap = function (x, theta, makePlot=FALSE) {
  n = length(x)
  t = max(x)
  B = 4000
  tstar = numeric(B)
  for (i in 1:B) {
    xstar = runif(n, min=3, max=theta)
    tstar[i] = max(xstar)
  }
  
  pl = sum(tstar<t) / B
  pr = sum(tstar>t) / B
  p = 2 * min(pl, pr) # e.g. 0.038
  
  if (makePlot) {
  # make histogram:
    hist(tstar,prob=T, main="Histogram of tstar", freq=F)
    lines(rep(t,2), c(0,0.03), col="red", lwd=2)
    axis(1,t,expression(paste("t")))
    print(sprintf("p = %.4f", p))
  }
  #return(p >= 0.05);
  return(data.frame(theta=theta, p=p, valid=(p>=0.05)))
}

#results = data.frame(p=c(), valid=c())
results = NULL
for (theta in seq(3,12,0.25)){
  cur = 
    doBootstrap(data$After8weeks, theta, makePlot=FALSE)
  if (is.null(results)) {
    results = cur
  } else {
    results = rbind(results, cur)
  }
}
plot(results$theta, results$p, main="P value vs Theta")
results
#sprintf("res = %d", res)
```

<!--# TODO: undestand why you do 2 * min(pl, pr) -->

You could use the Kolmogorv-Smirnov test here as well, by generating a
sample of values $(Y_1, â€¦, Y_n) \sim Unif(3, \theta)$ for a given
\$\\theta\$, allowing you to evaluate if the original data sample could
also be from the same distribution. Technically you could run this test
many times, for many generated samples \$Y\$, allowing you to more
robustly verify the results (as the particular values of $Y$).

**e)**

```{r}
res = binom.test(sum(data$After8weeks >= 6), length(data$After8weeks), p=0.5, alt="less")
```

The p-value from the sign-test is `r res$p.value` \> 0.05 so we fail to
reject $H_0: m \ge 6$, so the test suggests that the median cholesterol
level after 8 weeks of low fat diet is not less than 6.

```{r}
binom.test(sum(data$After8weeks <= 4.5), length(data$After8weeks), p=0.25, alt="g")
```

TODO: consider doing a proportion test like in 1d.

TODO: either way elaborate on answer

## Exercise 3: Diet

**a)**

```{r}
data = read.table("diet.txt", header=T)
# compute weight lost
data$weightlost = data$preweight - data$weight6weeks

par(mfrow = c(1, 3))
ylim = c(-3, 10)

diet1 = dplyr::filter(data, diet == 1)
diet2 = dplyr::filter(data, diet == 2)
diet3 = dplyr::filter(data, diet == 3)

boxplot(diet1$weightlost, main="Diet 1", ylab="Weight Lost (kg)", ylim=ylim)
boxplot(diet2$weightlost, main="Diet 2", ylab="Weight Lost (kg)", ylim=ylim)
boxplot(diet3$weightlost, main="Diet 3", ylab="Weight Lost (kg)", ylim=ylim)

stripchart(diet1$weightlost, main="Diet 1", ylab="Weight Lost (kg)", ylim=ylim, vertical=T)
stripchart(diet2$weightlost, main="Diet 2", ylab="Weight Lost (kg)", ylim=ylim, vertical=T)
stripchart(diet3$weightlost, main="Diet 3", ylab="Weight Lost (kg)", ylim=ylim, vertical=T)
```

```{r}
par(mfrow=c(1,2))
hist(data$preweight, freq=F)
qqnorm(data$preweight, main="Normal QQ plot: preweight")
shapiro.test(data$preweight)

hist(data$weight6weeks, freq=F)
qqnorm(data$weight6weeks, main="Normal QQ plot: weight6weeks")
shapiro.test(data$weight6weeks)

boxplot(data.frame(preweight=data$preweight, weightweeks6=data$weight6weeks))
```

Based on the histograms, normal qq plots, and shapiro-wilk test results
(with weight6weeks having $p<0.05$), normality seems doubtful for these
variables (certainly for weight6weeks at least).

Additionally, while the two variables appear symmetric based on the
boxplots, the histogram for preweight casts some doubt into the symmetry
of the data, so we'll use the sign test as a safe way to compare the
median difference between these two variables.

<!--# TODO: ask TA if this is the right interpretation -->

(Note that we assume this question wants us to combine the sub-datasets
of the 3 diets, into a larger dataset that doesn't consider the type of
diet).

```{r}
res = binom.test(sum(data$weightlost <= 0), length(data$weightlost), p=0.5, alt="two.sided")
```

The results of the sign test with p=`r res$p.value` \< 0.05 led us to
reject the $H_0: m \le 0$ (that the median difference in weight before
and after the diet is 0 or less).

<!--# TODO: ask professor, wouldn't sum(data$weightlost == 0) always be 0 when H_0 is m =m_0  -->

**b)**

First we check for normality in the diet datasets:

```{r}
# checking normality
checkNorm = function(data, name) {
  hist(data, main=sprintf("histogram of %s", name))
  qqnorm(data, main=sprintf("Normal qqplot of %s", name))
  shapiro.test(data)
}
par(mfrow = c(1, 2))
checkNorm(diet1$weightlost, "Diet 1"); checkNorm(diet2$weightlost, "Diet 2"); checkNorm(diet3$weightlost, "Diet 3"); 
```

Results suggest that normality is doubtful (for at least diet 1 and 3).
We will proceed with ANOVA anyways as instructed.

Note we'll use the `aov` function over `lm` because this is an
unbalanced experiment (diet1 has a smaller sample size than the others).

```{r}
#dietFrame = data.frame(diet1$weightlost, diet2$weightlost, diet3$weightlost)
# https://stackoverflow.com/a/8320687
dietFrame = data.frame(
  weightlost=c(diet1$weightlost, diet2$weightlost, diet3$weightlost),
  diet=factor(rep(c("diet1", "diet2", "diet3"), times=c(length(diet1$weightlost), length(diet2$weightlost), length(diet3$weightlost))))
)
#dietaov = aov(weightlost~diet, data=dietFrame)


# convert diet from int -> string (for informing linear model)!!
data$diet = as.character(data$diet)

dietaov = lm(weightlost~diet, data=data)
#print("dietaov:"); dietaov
print("summary(dietaov):"); summary(dietaov)
print("anova:"); anova(dietaov)
```

```{r}

```

## Exercise 4: Yield of Peas

```{r}
library(MASS)
data = npk
#data
```
