---
title: "Assignment 2: Group 45"
author: "Daniel Engbert, Rik Timmer, Koen van der Pool"
date: "03 March 2023"
output: pdf_document
fontsize: 11pt
highlight: tango
editor_options: 
  markdown: 
    wrap: 72
---

```{r, echo=FALSE}
options(digits=3) # e.g. for anova and summary() outputs...

# prevent code lines from being cutoff when too long:
#   (must install "formatR" package)
#   https://stackoverflow.com/a/66753995
#knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 75), tidy = TRUE)

# helper function to check normality throughout this assignment
checkNorm = function(data, name, unit="") {
  xlab = name
  if (unit != "") {
    xlab = sprintf("%s (%s)", name, unit)
  }
  hist(data, main=sprintf("Histogram of %s", name), xlab=xlab)
  qqnorm(data, main=sprintf("Normal qqplot of %s", name))
  res = shapiro.test(data)
  print(sprintf("Shapiro-Wilk normality p-value for %s: %.3f", name, res$p.value))
  return(res$p.value)
}

printPval = function(pval) {
  print(sprintf("p-value = %.3f", pval))
}

conclude = function(pval, hypothesis, type="test") {
  if (pval < 0.05) {
    return(sprintf("the p-value $%.3f<0.05$ for this %s suggests is sufficient evidence to reject the $H_0$ (%s).", pval, type, hypothesis));
  } else {
    return(sprintf("the p-value $%.3f>0.05$ for this %s suggests there's insufficient evidence to reject the $H_0$ (%s).", pval, type, hypothesis));
  }
}
```

Note: we made a function `checkNorm()` which prints a histogram, qqplot,
and p-value from the shapiro-wilk normality test. And we made a function
`printPval()` which simply prints a given p-value to 3 significant
figures. We utilize both functions throughout this assignment.

## Exercise 1: Trees

### 1 a)

<!--# TODO: check assumptions for ANOVA regarding normality -->

```{r}
trees = read.table("treeVolume.txt", header=T)
model = lm(volume~type, data=trees)
print("model coefficients:"); summary(model)$coefficients
res = anova(model)
sprintf("ANOVA p-value for type = %.3f", res["type", "Pr(>F)"])
```

The p-value $0.174>0.05$ for the type in the ANOVA analysis of the
linear model, suggests there's insufficient evidence to reject the $H_0$
(that tree type influences volume).

```{r, fig.height=2.75, fig.width=5, echo=FALSE}
oaks = dplyr::filter(trees, type == "oak")
beeches = dplyr::filter(trees, type != "oak")
par(mfrow = c(1, 2))
# making plots 
pval = checkNorm(oaks$volume, "oak")
pval = checkNorm(beeches$volume, "beech")

sprintf("oak mean volume = %.3f, beech mean volume = %.3f", mean(oaks$volume), mean(beeches$volume))

# note:: we don't have to actually do this t test
res = t.test(oaks$volume, beeches$volume)
#printPval(res$p.value)
```

<!--# TODO: beech isn't normal, oak appears somewhat doubtful, so maybe we can say "it could be done in principle IF the data was normal, but that's not the case here..." -->

We can split the data into two samples of tree volume based on the tree
types, and compare the means of the samples using a t-test to determine
whether, based on this data, there is a significant difference in mean
volume between the two tree types. As can be seen in the output of the
t-test $0.166 > 0.05$, signifying once again that there is not enough
evidence to reject the null hypothesis that the means of the samples are
the same. This concurs with the results of the ANOVA.

```{r}
new_oak = data.frame(type="oak"); new_beech = data.frame(type = "beech")
pred1 = predict(model, new_oak); pred2 = predict(model, new_beech)
sprintf("predicted volumes: oak = %.3f, beech = %.3f", pred1, pred2)
```

### 1 b)

```{r}
model = lm(volume~type*diameter + height, data=trees)
res = anova(model)
sprintf("ANOVA p-value for type:diameter = %.3f", res["type:diameter", "Pr(>F)"])
```

We built a linear model that added an interaction term between diameter
and type,
`r conclude(res["type:diameter", "Pr(>F)"], "that the influence of diameter on volume is the same for both tree types", type="term")`

```{r}
model = lm(volume~type*height + diameter, data=trees)
res = anova(model)
sprintf("ANOVA p-value for type:diameter = %.3f", res["type:height", "Pr(>F)"])
```

Now running another linear model that includes an interaction term
between height and type instead,
`r conclude(res["type:height", "Pr(>F)"], "that the influence of height on volume is the same for both tree types", type="term")`

So based on the results from our two models above, there's insufficient
evidence to suggest that the influences of diameter and height aren't
similar for both tree types.

### 1 c)

We construct a linear model to investigate how diameter, height and type
influence volume.

```{r}
#model = lm(volume~type+height+diameter, data=trees)
model = lm(volume~diameter+height+type, data=trees)
print("model coefficients:"); summary(model)$coefficients
print("anova:"); res = anova(model); res
```

<!--# TODO crispy code output^ -->

<!--# TODO: is the conclusion about type correct? the order of variables appears to affect the results... -->

Based on the ANOVA p-values, type is not a significant predictor for
volume (p-value $0.143 > 0.05$), while height and diameter are
significant (p-values less than 0.05). Diameter and height are both
positively correlated with the volume, with diameter having the largest
contribution (coefficient) of the two.

```{r}
# build better model where type isn't considered
modelC = lm(volume~height+diameter, data=trees)

avgTree = data.frame(height=mean(trees$height), diameter=mean(trees$diameter))
pred = predict(modelC, avgTree)
sprintf("predicted volume of average tree = %.3f", pred)
# mean(trees$volume) # this also gives the same result as expected

r2 = summary(modelC)$r.squared; ar2 = summary(modelC)$adj.r.squared
sprintf("modelC: R^2 = %.3f, Adj. R^2 = %.3f", r2, ar2)
```

Using the resulting model, the volume of a tree with the average height
and diameter is predicted to be `r sprintf("%.3f", pred)` .

### 1 d)

We propose to transform the data to create a new column that contains
the volume of a (theoretical) cylinder based on the tree's diameter and
height. (Note we omit tree type from the model as we found it to not be
a significant predictor above).

<!--# TODO: ask what units are, because this volume calculation should consider them?? -->

```{r}
# create predictor as cylinderical volume
#trees$cylinder = trees$diameter * pi * trees$height
trees$cylinder = pi * (trees$diameter / 2)^2 * trees$height

modelD = lm(volume~cylinder, data=trees)
print("model coefficients:"); summary(modelD)$coefficients
r2 = summary(modelD)$r.squared; ar2 = summary(modelD)$adj.r.squared
sprintf("model: R^2 = %.3f, Adj. R^2 = %.3f", r2, ar2)
print("ANOVA:"); anova(modelD)
```

After constructing a linear model for predicting the actual tree volume
from our proposed cylindrical estimator, we see that the cylinder
variable is a significant predictor of volume (p \< 0.05). The adjusted
$R^2$ values (and the regular $R^2$ values) for this model are both
greater than that of the model in part c), so this model appears to be
superior to using just the provided height and diameter variables in the
model.

<!--# TODO: we could also argue that the cylinder field summarizes / reduces the dimensionality from R^2 -> R, so it's arguably a simpler model? -->

## Exercise 2: Expenditure on criminal activities

### 2 a)

```{r, fig.height=4.5}
crimes = read.table("expensescrime.txt", header=T)
pairs(crimes[,-1])
crimes$state = factor(crimes$state)

model = lm(expend~bad+crime+lawyers+employ+pop, data=crimes)
summary(model)$coefficients
anova(model)

print('model 2:')
model = lm(expend~crime+bad+lawyers+employ+pop, data=crimes)
summary(model)$coefficients
anova(model)

# sorting by population
#crimes[order(crimes$pop, decreasing=TRUE),]
#crimes
```

```{r, fig.height=3.5}
n = length(crimes[,1])
dists = cooks.distance(model)
plot(1:n, dists, type="b", main="Cook's Distance by Dataset Index")
abline(1, 0, col = 'red') # plot y=1 for reference

# these are the indices into crimes that are cook's points
print("Influence points:"); crimes[dists > 1,]

# investigating collinearity
cor(crimes[,-1])
# using 0.8 as a threshold to help with visiblility:
res = cor(crimes[,-1])
res[res >= 0.8] = T; res[res <= 0.8] = F; res
```

Based on the correlation coefficients, it appears that all the
explanatory variables are correlated with each other, except for crime
which has no correlation with any of the other variables (its highest
correlation coefficient is 0.375). The other variables all have a
correlation coefficient of at least 0.832 between each other.

<!--# TODO ask TA about what a fair threshold is? -->

### 2 b)

```{r}
evalModel = function(model, name) {
  r2 = summary(model)$r.squared; ar2 = summary(model)$adj.r.squared
  pVal = summary(model)$coefficients[name, "Pr(>|t|)"]
  cat(sprintf("adding var '%s'\t\tPr(>|t|) =  %.3f, model R^2 = %.3f\n", name, pVal, r2))
}

doStepUp = function() {
  cat("\n****round1****\n")
  evalModel(lm(expend~bad, data=crimes), name="bad")
  evalModel(lm(expend~crime, data=crimes), name="crime")
  evalModel(lm(expend~lawyers, data=crimes), name="lawyers")
  evalModel(lm(expend~employ, data=crimes), name="employ")
  evalModel(lm(expend~pop, data=crimes), name="pop")
  
  # employ has highest adj. R^2 (0.954) and is significant
  cat("\n****round2****\n")
  evalModel(lm(expend~employ+bad, data=crimes), name="bad")
  evalModel(lm(expend~employ+crime, data=crimes), name="crime")
  evalModel(lm(expend~employ+lawyers, data=crimes), name="lawyers")
  evalModel(lm(expend~employ+pop, data=crimes), name="pop")
}
doStepUp()
```

In the 1st round of the "step up" method we found "employ" to lead to
the model with the largest $R^2$, while still being statistically
significant. In the 2nd round, "lawyers" was found to lead to the
largest increase in $R^2$ while still being statistically significant,
however the increase in $R^2$ was only $0.963-0.954=0.009$, which is
quite low, so we don't deem it worth adding to the model. (And so our
final model is `lm(expend~employ, data=crimes)`).

The result of the "step up" method suggesting that the model should only
have one explanatory variable ("employ") is not surprising as we showed
further above that all the variables (except for "crime") are collinear.

### 2 c)

<!--# Reference: Lecture 8, slide 13 -->

```{r, fig.height=3}
model = lm(expend~employ, data=crimes) # result of part 2b
state = data.frame(bad=50, crime=5000, lawyers=5000, employ=5000, pop=5000)
predict(model, state, interval="prediction")
```

The predicted interval $[-407, 642]$ can be improved by adjusting it to
$[0, 642]$ as we know the expenditure must be a positive number. So
we're 95% confident that the expenditure by this hypothetical state
would be between \$0 and \$642,000.

### 2 d)

```{r, results='hide', message=F}
library(glmnet)
```

```{r, fig.height=4, fig.width=8}
par(mfrow=c(1,2))
#set.seed(444) # ensuring results don't change each time its run
x = as.matrix(crimes[,-1]) # remove states column
x = x[,-1] # remove expenditure
y = crimes[,2]

train = sample(1:nrow(x),0.67*nrow(x))
x.train = x[train,]; y.train = y[train]
x.test = x[-train,]; y.test = y[-train] 

lm.model = lm(expend~bad+crime+lawyers+employ+pop,data=crimes, subset=train)
y.predict.lm = predict(lm.model,newdata=crimes[-train,])
mse.lm = mean((y.test-y.predict.lm)^2)
sprintf("linear model mse = %.3f", mse.lm)

lasso.model = glmnet(x.train,y.train,alpha=1)
lasso.cv = cv.glmnet(x.train,y.train,alpha=1,type.measure="mse",nfolds=5)

plot(lasso.model,label=T,xvar="lambda")
plot(lasso.cv) 

lambda.min = lasso.cv$lambda.min; lambda.1se=lasso.cv$lambda.1se; 
sprintf("lambda.min = %.3f, lambda.1se = %.3f", lambda.min, lambda.1se)

coef(lasso.model,s=lasso.cv$lambda.min) 
coef(lasso.model,s=lasso.cv$lambda.1se) 

lasso.pred1 = predict(lasso.model,s=lambda.min,newx=x.test) 
lasso.pred2 = predict(lasso.model,s=lambda.1se,newx=as.matrix(x.test))
mse1.lasso = mean((y.test-lasso.pred1)^2)
mse2.lasso = mean((y.test-lasso.pred2)^2)
sprintf("mse1 = %.3f, mse2 = %.3f", mse1.lasso, mse2.lasso)
```

<!--# REMINDER: The output of the lasso model changes with every run, so make sure the conclusion fits with the output!!! -->

<!--# TODO: add better interpretation... -->

As we can see from the lambdas calculated by the model above, for the
minimum error, the relevant variables are bad, crime, lawyers, and
employ. To obtain a reduced model that is within one standard error of
the minimum, we can take into account only bad, lawyers, and employ. In
general the model is very similar to the one in b). While in b), the
variables that were collinear could have been added to the model to
improve the \$R\^2\$, we chose not to do so because the improvement was
marginal. The lasso model does something similar, in that it selects one
of the aforementioned variables as the primary factor (which has a large
coefficient), and the other (believed to be collinear) variables that
are shown as relevant by the lasso model have very small coefficients,
because as we saw, they had very little effect on the $R^2$ in b).

## Exercise 3: Titanic

### 3 a)

```{r, fig.height=3.5, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
titanic = read.table("titanic.txt", header=T)
titanic$PClass = factor(titanic$PClass)
titanic$Sex = factor(titanic$Sex)
#titanic$Survived = factor(titanic$Survived)

library(plyr)
# round age to nearest 10 years (https://stackoverflow.com/a/6466894)
titanic$Ager = round_any(titanic$Age, 20)
titanic$Ager = factor(titanic$Ager)
titanic$Age2 = titanic$Age^2

print("total number of individuals for each combination of class and gender:")
tot = xtabs(~PClass+Sex, data=titanic); tot

print("Survival rate by class and gender combinations:")
totc = xtabs(Survived~PClass+Sex, data=titanic); round(totc/tot, 2)

#plot(titanic$Age, y=titanic$Survived, xlim=c(0, 100))
totage = xtabs(~Age, data=titanic)
barplot(xtabs(Survived~Age,data=titanic)/totage, main="% Survival by Age Group", xlab="Age Group", ylab="Survival Ratio")

# build logistic regression model
model = glm(Survived~Age+Sex+PClass,data=titanic, family=binomial)
summary(model)

plot(titanic$Age,exp(3.759662 + titanic$Age*-0.039177), ylab="Odds of Survival", xlab="Age (years)",main="Survival Odds of a First Class Female by Age")
```

<!--# TODO: Look at going for age vs ager when attempting to interpret odds -->

<!--# TODO: larger binsize for boxplot... -->

In the model above, the intercept can be interpreted as a female who
traveled in 1st class. We can see that other classes (namely 2nd and
3rd) lower the odds of survival by the negative coefficients, where 3rd
class has a larger impact than 2nd. Similarly, an increase in age has a
negative impact on survival odds, however the impact is low because of
the parabolic shape of the graph shown above. How we interpret this is
that the fact that very young and very old people have the highest
survival rates are balancing each other out to form a coefficient that
is close to 0, which inaccurately represents the actual relationship
between age and survival, because it is clear that it does have an
effect. Finally the odds of survival of a male are also significantly
lower than that of a female, as shown by the negative coefficient.

### 3 b)

```{r}
ageclass_model = glm(Survived~Age*PClass+Sex,data=titanic, family=binomial)
summary(ageclass_model)

agesex_model = glm(Survived~Age*Sex+PClass,data=titanic, family=binomial)
summary(agesex_model)

male1 = data.frame(Age=55, Sex = "male", PClass = "1st")
male2 = data.frame(Age=55, Sex = "male", PClass = "2nd")
male3 = data.frame(Age=55, Sex = "male", PClass = "3rd")
female1 = data.frame(Age=55, Sex = "female", PClass = "1st")
female2 = data.frame(Age=55, Sex = "female", PClass = "2nd")
female3 = data.frame(Age=55, Sex = "female", PClass = "3rd")

predict(model,female1, type="response")
predict(model,female2, type="response")
predict(model,female3, type="response")
predict(model,male1, type="response")
predict(model,male2, type="response")
predict(model,male3, type="response")
```

Given the results of the two models produced here, as well as the one
from 3a), we will select the model that considers the interaction
between sex and age, given that the model found that the interaction was
significant (the model in 3a) found that sex and age by themselves were
also significant). Furthermore, the model that considered the
interaction between age and class found that the interaction was not
significant ($P > 0.05$ for both 2nd class and 3rd class).

The estimates for the probability of survival of each of the
combinations of factors is as shown below:

<!--# TODO: is it okay to round ages? -->

<!--# TODO: clean up after me pls daddy Dan -->

### 3 c)

We propose to do k-fold cross-validation, using 10% of the data in each
fold, and calculating the average prediction accuracy per combination of
factor levels. We would use a slightly modified version of the model
from 3b), namely
`glm(Survived~Ager*Sex+PClass,data=titanic, family=binomial)` , where
the difference would be that the age would be split into several groups
(represented as the variable `Ager`.

To be able to predict for the odds resulting from the model, we would
use a threshold of 1, where if the odds were above 1, the subject would
be predicted as survived and not survived otherwise. (Because when the
odds are $\ge 1$ , there's a $\ge 50\%$ chance of survival).

### 3 d)

Based on the (3x2) table in part 3a, every unique combination of classes
in this dataset has $>5$ individuals, so a chi-squared test is
applicable.

To investigate the effect of the factors `PClass` and `Sex` separately,
we'll perform two separate chisquare tests which each test the
significance of a single factor.

```{r}
# build contigency table
cont1 = as.matrix(xtabs(~PClass, data=titanic)); cont1
chisq.test(cont1)

cont2 = as.matrix(xtabs(~Sex, data=titanic)); cont2
chisq.test(cont2)
```

Both chisquare tests yield p-values $<0.05$ so we reject the null
hypotheses that Sex and PClass aren't significantly explanatory
variables for predicting survival.

### 3 e)

Comparing the linear regression approach vs the chisquare approach, the
linear regression approach has the advantage of being able to make
predictions on a given individual's chance of survival (which chisquare
has no ability to do), and the linear regression approach can give
p-values for each variable.

Both methods can also give insights into the significance of explanatory
variables.

## Exercise 4: Military Coups

### 4 a)

```{r}
coups = read.table("coups.txt", header=T)
coups$pollib=factor(coups$pollib)

coupsglm = glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size+numelec+numregim, family=poisson, data=coups)
summary(coupsglm)
```

As can be seen by the results of the Poisson model above, it is seen
that the variables $oligarchy$, $pollib$, and $parties$ are seen as
significant in predicting the number of successful military coups from
independence to 1989.

### 4 b)

```{r,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# prints just the top 3 least significant coefficients of a model:
evalModel = function(model, name) {
  cat(sprintf("\n%s:\n", name))
  res = summary(model)$coefficients
  print(head(res[order(res[,4], decreasing=T),], n=3))
}

coupsglm1 = glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size+numelec+numregim, family=poisson, data=coups)
evalModel(coupsglm1, "coupsglm1")
# numelec has highest p-value (0.6705) so we remove it

coupsglm2 = glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size+numregim, family=poisson, data=coups)
evalModel(coupsglm2, "coupsglm2")
# numregim has highest p-value so we remove it

coupsglm3 = glm(miltcoup~oligarchy+pollib+parties+pctvote+popn+size, family=poisson, data=coups)
evalModel(coupsglm3, "coupsglm3")
# size has highest p-value so we remove it

coupsglm4 = glm(miltcoup~oligarchy+pollib+parties+pctvote+popn, family=poisson, data=coups)
evalModel(coupsglm4, "coupsglm4")
# popn has highest p-value so we remove it

coupsglm5 = glm(miltcoup~oligarchy+pollib+parties+pctvote, family=poisson, data=coups)
evalModel(coupsglm5, "coupsglm5")
# pctvote has highest p-value so we remove it

coupsglm6 = glm(miltcoup~oligarchy+pollib+parties, family=poisson, data=coups)
evalModel(coupsglm6, "coupsglm6")
#print("coupsglm6:"); summary(coupsglm6)$coefficients
```

<!--# TODO: shouldn't we remove 'pollib1' actually? instead of pctvote...??? -->

The number of explanatory variables was reduced following the step-down
approach, and in doing so the variables were removed in the following
order: $numelec$, $numregim$, $size$ $popn$, $pctvote$. This left the
model with only relevant explanatory variables (significant as
$P < 0.05$). These variables were the same as those seen as relevant in
the previous model in 4a), namely $oligarchy$, $pollib$, and $parties$.

### 4 c)

```{r}
country1 = data.frame(oligarchy = mean(coups$oligarchy),
  pollib = factor(0), parties = mean(coups$parties))
country2 = data.frame(oligarchy = mean(coups$oligarchy),
  pollib = factor(1), parties = mean(coups$parties))
country3 = data.frame(oligarchy = mean(coups$oligarchy),
  pollib = factor(2), parties = mean(coups$parties))

printResults = function() {
  print(sprintf("country1 prediction = %.3f", predict(coupsglm6, country1, type="response")))
  print(sprintf("country2 prediction = %.3f", predict(coupsglm6, country2, type="response")))
  print(sprintf("country3 prediction = %.3f", predict(coupsglm6, country3, type="response")))
}
printResults()
```

Using the model from 4b), we found that the coefficient of $pollib$ was
significant and negative. This entails that with an increase in the
value of the political liberalization (i.e. with an increase in civil
rights), there would be a decrease in the predicted number of successful
military coups. The predictions above confirm this.
