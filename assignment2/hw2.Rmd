---
title: "Assignment 2: Group 45"
author: "Daniel Engbert, Rik Timmer, Koen van der Pool"
date: "03 March 2023"
output: pdf_document
fontsize: 11pt
highlight: tango
editor_options: 
  markdown: 
    wrap: 72
---

```{r, echo=FALSE}
options(digits=3) # e.g. for anova and summary() outputs...

# helper function to check normality throughout this assignment
checkNorm = function(data, name, unit="") {
  xlab = name
  if (unit != "") {
    xlab = sprintf("%s (%s)", name, unit)
  }
  hist(data, main=sprintf("Histogram of %s", name), xlab=xlab)
  qqnorm(data, main=sprintf("Normal qqplot of %s", name))
  res = shapiro.test(data)
  print(sprintf("Shapiro-Wilk normality p-value for %s: %.3f", name, res$p.value))
  return(res$p.value)
}

printPval = function(pval) {
  print(sprintf("p-value = %.3f", pval))
}

conclude = function(pval, hypothesis, type="test") {
  if (pval < 0.05) {
    return(sprintf("the p-value $%.3f<0.05$ for this %s suggests is sufficient evidence to reject the $H_0$ (%s).", pval, type, hypothesis));
  } else {
    return(sprintf("the p-value $%.3f>0.05$ for this %s suggests there's insufficient evidence to reject the $H_0$ (%s).", pval, type, hypothesis));
  }
}
```

Note: we made a function `checkNorm()` which prints a histogram, qqplot,
and p-value from the shapiro-wilk normality test. And we made a function
`printPval()` which simply prints a given p-value to 3 significant
figures. We utilize both functions throughout this assignment.

## Exercise 1: Trees

### 1 a)

<!--# TODO: check assumptions for ANOVA regarding normality?? -->

```{r}
trees = read.table("treeVolume.txt", header=T)
model = lm(volume~type, data=trees)
print("model coefficients:"); summary(model)$coefficients
res = anova(model)
sprintf("ANOVA p-value for type = %.3f", res["type", "Pr(>F)"])
```

The p-value $0.174>0.05$ for the type in the ANOVA analysis of the
linear model, suggests there's insufficient evidence to reject the $H_0$
(that tree type influences volume).

```{r, fig.height=4.5, fig.width=4.5, echo=FALSE}
oaks = dplyr::filter(trees, type == "oak")
beeches = dplyr::filter(trees, type != "oak")
par(mfrow = c(2, 2))
# making plots 
pval = checkNorm(oaks$volume, "oak")
pval = checkNorm(beeches$volume, "beech")

sprintf("oak mean volume = %.3f, beech mean volume = %.3f", mean(oaks$volume), mean(beeches$volume))

# TODO: we don't have to actually do this t test
#res = t.test(oaks$volume, beeches$volume)
#printPval(res$p.value)
```

<!--# TODO: beech isn't normal, oak appears somewhat doubtful, so maybe we can say "it could be done in principle IF the data was normal, but that's not the case here..." -->

We can split the data into two samples of tree volume based on the tree
types, and compare the means of the samples using a t-test to determine
whether, based on this data, there is a significant difference in mean
volume between the two tree types. As can be seen in the output of the
t-test $0.166 > 0.05$, signifying once again that there is not enough
evidence to reject the null hypothesis that the means of the samples are
the same. This concurs with the results of the ANOVA.

```{r}
new_oak = data.frame(type="oak"); new_beech = data.frame(type = "beech")
pred1 = predict(model, new_oak); pred2 = predict(model, new_beech)
sprintf("predicted volumes: oak = %.3f, beech = %.3f", pred1, pred2)
```

### 1 b)

```{r}
model = lm(volume~type*diameter + height, data=trees)
res = anova(model)
sprintf("ANOVA p-value for type:diameter = %.3f", res["type:diameter", "Pr(>F)"])
```

We built a linear model that added an interaction term between diameter
and type,
`r conclude(res["type:diameter", "Pr(>F)"], "that the influence of diameter on volume is the same for both tree types", type="term")`

```{r}
model = lm(volume~type*height + diameter, data=trees)
res = anova(model)
sprintf("ANOVA p-value for type:diameter = %.3f", res["type:height", "Pr(>F)"])
```

Now running another linear model that includes an interaction term
between height and type instead,
`r conclude(res["type:height", "Pr(>F)"], "that the influence of height on volume is the same for both tree types", type="term")`

So based on the results from our two models above, there's insufficient
evidence to suggest that the influences of diameter and height aren't
similar for both tree types.

### 1 c)

We construct a linear model to investigate how diameter, height and type
influence volume.

```{r}
model = lm(volume~type+height+diameter, data=trees)
print("model coefficients:"); summary(model)$coefficients
print("anova:"); res = anova(model); res
```

<!--# TODO crispy code output^ -->

<!--# TODO: is the conclusion about type correct? -->

Based on the ANOVA p-values, type is not a significant predictor for
volume (p-value $0.143 > 0.05$), while height and diameter are
significant (p-values less than 0.05). Diameter and height are both
positively correlated with the volume, with diameter having the largest
contribution (coefficient) of the two.

```{r}
# build better model where type isn't considered
modelC = lm(volume~height+diameter, data=trees)

avgTree = data.frame(height=mean(trees$height), diameter=mean(trees$diameter))
pred = predict(modelC, avgTree)
sprintf("predicted volume of average tree = %.3f", pred)
# mean(trees$volume) # this also gives the same result as expected

r2 = summary(modelC)$r.squared; ar2 = summary(modelC)$adj.r.squared
sprintf("modelC: R^2 = %.3f, Adj. R^2 = %.3f", r2, ar2)
```

Using the resulting model, the volume of a tree with the average height
and diameter is predicted to be `r sprintf("%.3f", pred)` .

### 1 d)

We propose to transform the data to create a new column that contains
the volume of a (theoretical) cylinder based on the tree's diameter and
height. (Note we omit tree type from the model as we found it to not be
a significant predictor above).

<!--# TODO: ask what units are, because this volume calculation should consider them?? -->

```{r}
# create predictor as cylinderical volume
trees$cylinder = trees$diameter * pi * trees$height

modelD = lm(volume~cylinder, data=trees)
print("model coefficients:"); summary(modelD)$coefficients
r2 = summary(modelD)$r.squared; ar2 = summary(modelD)$adj.r.squared
sprintf("model: R^2 = %.3f, Adj. R^2 = %.3f", r2, ar2)
print("ANOVA:"); anova(model)
```

After constructing a linear model for predicting the actual tree volume
from our proposed cylindrical estimator, we see that the cylinder
variable is a significant predictor of volume (p \< 0.05). However the
adjusted $R^2$ values (and the regular $R^2$ values) for this model are
less than that of the model in part c), so while cylinder is a useful
predictor, it's still inferior to using just the provided height and
diameter variables in the model.

<!--# TODO: we could also argue that the cylinder field summarizes / reduces the dimensionality from R^2 -> R, so it's arguably a simpler model? -->

## Exercise 2: Expenditure on criminal activities

### 2 a)

```{r, fig.height=7}
crimes = read.table("expensescrime.txt", header=T)
pairs(crimes[,-1])
crimes$state = factor(crimes$state)


model = lm(expend~bad+crime+lawyers+employ+pop, data=crimes)
summary(model)$coefficients
anova(model)

print('model 2:')
model = lm(expend~crime+bad+lawyers+employ+pop, data=crimes)
summary(model)$coefficients
anova(model)

# sorting by population
#crimes[order(crimes$pop, decreasing=TRUE),]



#crimes
```

```{r, fig.height=3.5}
n = length(crimes[,1])
dists = cooks.distance(model)
plot(1:n, dists, type="b")
abline(1, 0, col = 'red') # plot y=1 for reference

# these are the indices into crimes that are cook's points
dists[dists > 1]
# TODO: print state names
#cooked = crimes[dists[dists > 1],]
#cooked

# investigating collinearity
cor(crimes[,-1])
res = cor(crimes[,-1])
# using 0.8 as a threshold to help with visiblility
res[res >= 0.8] = T; res[res <= 0.8] = F; 
res
```

Based on the correlation coefficients, it appears that all the
explanatory variables are correlated, except for crime which has no
correlation with any of the other variables (its highest correlation
coefficient is 0.375). The other variables all have a correlation
coefficient of at least 0.832 between each other.

<!--# TODO ask TA about what a fair threshold is? -->

### 2 b)

```{r}
evalModel = function(model, name) {
  print(sprintf("adding var '%s':", name))
  print(summary(model)$coefficients)
  r2 = summary(model)$r.squared; ar2 = summary(model)$adj.r.squared
  sprintf("model: R^2 = %.3f", r2)
}

evalModel(lm(expend~bad, data=crimes), name="bad")
evalModel(lm(expend~crime, data=crimes), name="crime")
evalModel(lm(expend~lawyers, data=crimes), name="lawyers")
evalModel(lm(expend~employ, data=crimes), name="employ")
evalModel(lm(expend~pop, data=crimes), name="pop")

# employ has highest adj. R^2 (0.955) and is significant
print("****round2****")
evalModel(lm(expend~employ+bad, data=crimes), name="bad")
evalModel(lm(expend~employ+crime, data=crimes), name="crime")
evalModel(lm(expend~employ+lawyers, data=crimes), name="lawyers")
evalModel(lm(expend~employ+pop, data=crimes), name="pop")
```

<!--# TODO: crispy code output -->

In the 1st round of the "step up" method we found "employ" to lead to
the largest $R^2$ model, while still being statistically significant.

In the 2nd round of the "step up" method, "lawyers" was found to lead to
the largest increase in $R^2$ while still being statistically
significant, however the increase in $R^2$ was only $0.963-0.954=0.009$,
which is quite low, so we don't deem it worth adding to the model.

The result of the "step up" method suggesting the model should only have
one explanatory variable ("employ") is not surprising as we showed
further above that all the variables (except for "crime") are collinear.

### 2 c)

<!--# Reference: Lecture 8, slide 13 -->

```{r}
model = lm(expend~employ, data=crimes) # result of part 2b
state = data.frame(bad=50, crime=5000, lawyers=5000, employ=5000, pop=5000)
predict(model, state, interval="prediction")
```

The predicted interval $[-407, 642]$ can be improved by adjusting it to
$[0, 642]$ as we know the expenditure must be a positive number. So
we're 95% confident that the expenditure by this hypothetical state
would be between \$0 and \$642,000.

### 2 d)

```{r}
mtcars # dataset mtcars: mpg is the response
x=as.matrix(mtcars[,-1])
y=mtcars[,1]

train=sample(1:nrow(x),0.67*nrow(x)) # train by using 2/3 of the x rows 
x.train=x[train,]; y.train=y[train]  # data to train
x.test=x[-train,]; y.test = y[-train] # data to test the prediction quality

# Prediction by using the linear model
# first fit linear model on the train data
lm.model=lm(mpg~cyl+disp+hp+drat+wt+qsec+vs+am+gear+carb,data=mtcars,subset=train)
y.predict.lm=predict(lm.model,newdata=mtcars[-train,]) # predict for the test rows
mse.lm=mean((y.test-y.predict.lm)^2); mse.lm # prediction quality by the linear model

# Now apply lasso for selecting the variables and prediction 
library(glmnet) 
lasso.model=glmnet(x.train,y.train,alpha=1) # alpha=1 for lasso
#more options: standardize=TRUE, intercept=FALSE,nlambda=1000
lasso.cv=cv.glmnet(x.train,y.train,alpha=1,type.measure="mse",nfolds=5)
# option nfolds=5 means 5-fold cross validation. By default, the method 
# performs 10-fold cross validation to choose the best lambda.
# plots
plot(lasso.model,label=T,xvar="lambda") #standardize=T,type.coef="2norm",xvar="norm") "coef"
#plot(lasso.cv$glmnet.fit,xvar="lambda",label=T) # the same plot
plot(lasso.cv) 
plot(lasso.cv$glmnet.fit,xvar="lambda",label=T)
# With label="T" in plot commando you see which curve corresponds 
# to which coefficients. The glmnet plot above shows the shrinkage of 
# the lasso coefficients as you move from the right to the left, 
# but unfortunately, it is not clearly labelled. 
# Lasso contrasts with ridge regression, which flattens out 
# everything, but does not zero out any of the regression coefficients.

lambda.min=lasso.cv$lambda.min; lambda.1se=lasso.cv$lambda.1se; 
lambda.min; lambda.1se # best lambda by cross validation
coef(lasso.model,s=lasso.cv$lambda.min) # cyl,hp,wt,am and carb are relevant
coef(lasso.model,s=lasso.cv$lambda.1se) # only cyl,hp and wt are releveant

# lambda.min is the value of lambda that gives minimum mean cross-validated 
# error. The other lambda saved is lambda.1se, which gives the most regularized 
# (reduced) model such that error is within one standard error of the minimum. 

lasso.pred1=predict(lasso.model,s=lambda.min,newx=x.test) 
lasso.pred2=predict(lasso.model,s=lambda.1se,newx=as.matrix(x.test))
mse1.lasso=mean((y.test-lasso.pred1)^2); mse1.lasso
mse2.lasso=mean((y.test-lasso.pred2)^2); mse2.lasso
```

```{r}
library(glmnet)



```

## Exercise 3: Titanic

### 3 a)

```{r}
titanic = read.table("titanic.txt", header=T)
#titanic
```

## Exercise 4: Military Coups

### 4 a)

```{r}
coups = read.table("coups.txt", header=T)
#coups
```
